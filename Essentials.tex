% -*- root: Main.tex -*-
\section{Essentials}
\subsection*{Matrix/Vector}
\begin{compactdesc}
	\item[Orthogonal:] (i.e. columns are orthonormal!) $\mathbf{A}^{-1} = \mathbf{A}^\top$, $\mathbf{A} \mathbf{A}^\top = \mathbf{A}^\top \mathbf{A} = \mathbf{I}$, $\operatorname{det}(\mathbf{A}) \in \{+1, -1\}$, $\operatorname{det}(\mathbf{A}^\top \mathbf{A}) = 1$
	\item[Inner Product:] $\langle \mathbf{x}, \mathbf{y} \rangle = \mathbf{x}^\top \mathbf{y} = \sum_{i=1}^{N} \mathbf{x}_i \mathbf{y}_i$.
	\begin{inparaitem}
		\item $\langle \mathbf{x} \pm \mathbf{y}, \mathbf{x} \pm \mathbf{y} \rangle = \langle \mathbf{x}, \mathbf{x} \rangle \pm 2 \langle \mathbf{x}, \mathbf{y} \rangle + \langle \mathbf{y}, \mathbf{y} \rangle$
		\item $\langle \mathbf{x}, \mathbf{y} + \mathbf{z} \rangle = \langle \mathbf{x}, \mathbf{y} \rangle + \langle \mathbf{x}, \mathbf{z} \rangle$
		\item $\langle \mathbf{x} + \mathbf{y}, \mathbf{z} \rangle = \langle \mathbf{x}, \mathbf{z} \rangle + \langle \mathbf{y}, \mathbf{z} \rangle$
		\item $\langle \mathbf{x}, \mathbf{y} \rangle = \|\mathbf{x}\|_2 \cdot \|\mathbf{y}\|_2 \cdot \cos(\theta)$
		\item If $\mathbf{y}$ is a unit vector then $\langle \mathbf{x}, \mathbf{y} \rangle$ projects $\mathbf{x}$ onto $\mathbf{y}$
	\end{inparaitem}
	\item[Outer Product:] $\mathbf{u} \mathbf{v}^\top$, $(\mathbf{u} \mathbf{v}^\top)_{i, j} = \mathbf{u}_i \mathbf{v}_j$
	\item[Transpose:] $(\mathbf{A}^\top)^{-1} = (\mathbf{A}^{-1})^\top$
	\item[Cross product:] $\vec{a}\times\vec{b}=(a_2b_3-a_3b_2, a_3b_1-a_1b_3, a_1b_2-a_2b_1)^\top$
    \item[A invertible:] $\mathbf{A}\mathbf{x} = \mathbf{0}$ iff $\mathbf{x} = \mathbf{0}$
\end{compactdesc}

\subsection*{Norms}
$\|\mathbf{x}\|_0 = |\{i | x_i \neq 0\}|$ \qquad $\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^{N} \mathbf{x}_i^2} = \sqrt{\langle \mathbf{x}, \mathbf{x} \rangle}$\\
$\|\mathbf{x}\|_p = \left( \sum_{i=1}^{N} |x_i|^p \right)^{\frac{1}{p}}$\\
$\|\mathbf{M}\|_F =\allowbreak \sqrt{\sum_{i=1}^{m} \sum_{j=1}^{n}\mathbf{m}_{i,j}^2} =\allowbreak \sqrt{\sum_{i=1}^{\min\{m, n\}} \sigma_i^2} = \sqrt{trace(A^\top A)} = \sqrt{trace(AA^\top)}$\\
$\|\mathbf{M}\|_1 = \sum_{i,j} | m_{i,j}|$ \qquad $\|\mathbf{M}\|_2 = \sigma_{\text{max}}(\mathbf{M})$\\
$\|\mathbf{M}\|_p = \max_{\mathbf{v} \neq 0} \frac{\|\mathbf{M}\mathbf{v}\|_p}{\|\mathbf{v}\|_p}$ \qquad $\|\mathbf{M}\|_\star = \sum_{i=1}^{\min(m, n)} \sigma_i$

\subsection*{Logarithm}
    $\log_b(AB) = \log_b(A) + \log_b(B)$ |
    $\log_b(\frac{A}{B}) = \log_b(A) - \log_b(B)$ |
    $\log_b(A^k) = k\log_b(A)$ |
    $\log_b(1) = 0$ |
    $\log_b(b) = 1$ |
    $\log_b(b^k) = k$ |
    $b^{\log_b(k)} = k$

\subsection*{Derivatives}
$\frac{\partial}{\partial \mathbf{x}}\mathbf{b}^\top \mathbf{x} = \frac{\partial}{\partial \mathbf{x}}(\mathbf{x}^\top \mathbf{b}) = \mathbf{b}$ |
$\frac{\partial}{\partial \mathbf{x}}\mathbf{x}^\top \mathbf{x} = 2\mathbf{x}$ |
$\frac{\partial}{\partial \mathbf{x}}\mathbf{x}^\top \mathbf{A}\mathbf{x} = (\mathbf{A}^\top + \mathbf{A})\mathbf{x}$ |
$\frac{\partial}{\partial \mathbf{x}}\mathbf{b}^\top \mathbf{A}\mathbf{x} = \mathbf{A}^\top \mathbf{b}$ |
$\frac{\partial}{\partial \mathbf{X}}\mathbf{c}^\top \mathbf{X} \mathbf{b} = \mathbf{c}\mathbf{b}^\top$ |
$\frac{\partial}{\partial \mathbf{X}}\mathbf{c}^\top \mathbf{X}^\top \mathbf{b} = \mathbf{b}\mathbf{c}^\top$ |
$\frac{\partial}{\partial \mathbf{x}}\| \mathbf{x}-\mathbf{b} \|_2 = \frac{\mathbf{x}-\mathbf{b}}{\|\mathbf{x}-\mathbf{b}\|_2}$ |
$\frac{\partial}{\partial \mathbf{x}}\|\mathbf{x}\|^2_2 = \frac{\partial}{\partial \mathbf{x}} (\mathbf{x}^\top \mathbf{x}) = 2\mathbf{x}$ |
$\frac{\partial}{\partial \mathbf{X}}\|\mathbf{X}\|_F^2 = 2\mathbf{X}$ |
$\frac{\partial}{\partial \mathbf{x}}\|\mathbf{Ax - b}\|_2^2 = \mathbf{2(A^\top Ax-A^\top b)}$ |
$\frac{\partial}{\partial \mathbf{x}}\log_b(x) = \frac{1}{x \ln(b)}$ |
$\frac{\partial}{\partial \mathbf{x}}\sqrt(x) = \frac{x^{-\frac{1}{2}}}{2}$ |
$\frac{\partial}{\partial \mathbf{x}}a^x = \log(a) a^x$ |
$\frac{\partial}{\partial \mathbf{x}}\ln(x) = \frac{1}{x}$ |
$\frac{\partial}{\partial \mathbf{x}}\sin(x) = \cos(x)$ |
$\frac{\partial}{\partial \mathbf{x}}\cos(x) = -\sin(x)$ |
$\frac{\partial}{\partial \mathbf{x}}\tan(x) = \sec^2(x)$\\
Product: $f g = f'g + fg'$ |
Quotient: $\frac{f}{g} = \frac{f'g - fg'}{g^2}$ \\
Reciprocal: $\frac{1}{f} = -\frac{f'}{f^2}$ |
Chain: $g(f(x)) = g'(f(x))f'(x)$

\subsection*{Eigenvalue / -vectors}
Eigenvalue Problem: $\mathbf{Ax} = \lambda \mathbf{x}$\\
1. solve $\operatorname{det}(\mathbf{A} - \lambda \mathbf{I}) \overset{!}{=} 0$ resulting in $\{\lambda_i\}_i$\\
2. $\forall \lambda_i$:
solve $(\mathbf{A} - \lambda_i \mathbf{I}) \mathbf{x}_i = \mathbf{0}$, for $\mathbf{x}_i$.

\subsection*{Eigendecomposition}
$\mathbf{A} \in \mathbb{R}^{N \times N}$ then $\mathbf{A} = \mathbf{Q} \boldsymbol{\Lambda} \mathbf{Q}^{-1}$ with $\mathbf{Q} \in \mathbb{R}^{N \times N}$, $\rightarrow$ $\mathbf{A}\mathbf{Q} = \mathbf{Q}\boldsymbol{\Lambda}$.\\
if fullrank: $\mathbf{A}^{-1} = \mathbf{Q} \boldsymbol{\Lambda}^{-1} \mathbf{Q}^{-1}$ and $(\boldsymbol{\Lambda}^{-1})_{i,i} = \frac{1}{\lambda_i}$.\\
if $\mathbf{A}$ symmetric: $A = \mathbf{Q} \boldsymbol{\Lambda} \mathbf{Q^\top}$ ($\mathbf{Q}$ orthogonal).

\subsection*{Probability / Statistics}
\begin{inparaitem}
	\item $P(x) := Pr[X = x] := \sum_{y \in Y} P(x, y)$
	\item $P(x|y) := Pr[X = x | Y = y] := \frac{P(x,y)}{P(y)},\quad \text{if } P(y) > 0$
	\item $\forall y \in Y: \sum_{x \in X} P(x|y) = 1$ (property for any fixed $y$)
	\item $P(x, y) = P(x|y) P(y)$
	\item $P(x|y) = \frac{P(y|x)P(x)}{P(y)}$ (Bayes' rule)
	\item $P(x|y) = P(x) \Leftrightarrow P(y|x) = P(y)$ (iff $X$, $Y$ independent)
	\item $P(x_1, \ldots, x_n) = \prod_{i=1}^n P(x_i)$ (iff IID)
    \item $\mathrm{E}[X] = \sum_{x \in X} x P(X = x)$
    \item $\mathrm{E}[g(x)] = \sum_{x \in X} g(x) P(X = x)$ (LoTUS)
    \item $\mathrm{Var}[X] = \mathrm{E}[(X - \mathrm{E}[X])^2] = \mathrm{E}[X^2] - \mathrm{E}[X]^2$
    \item $\mathrm{Var}[aX + b] = a^2 \mathrm{Var}[X]$
\end{inparaitem}

\subsection*{Jensen's Inequality}
$f(tx_1 + (1 - t)x_2) \leq tf(x_1) + (1 - t)f(x_2)$
